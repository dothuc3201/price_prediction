{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports các thư viện\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "\n",
    "import keras.utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Dense\n",
    "from keras.layers import GRU\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import tensorflow as tf\n",
    "import seaborn as sn\n",
    "import seed\n",
    "import os\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsi(data, period: int = 14):\n",
    "\n",
    "    delta = data[\"Close\"].diff()\n",
    "\n",
    "    up, down = delta.copy(), delta.copy()\n",
    "    up[up < 0] = 0\n",
    "    down[down > 0] = 0\n",
    "\n",
    "    gain = up.ewm(com=(period - 1), min_periods=period).mean()\n",
    "    loss = down.abs().ewm(com=(period - 1), min_periods=period).mean()\n",
    "\n",
    "    RS = gain / loss\n",
    "    return 100 - (100 / (1 + RS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lag granularity (độ trễ) - days or hours\n",
    "lag_granularity = \"hours\"\n",
    "#lag value\n",
    "lag = 1\n",
    "# type of analyser - TextBlob or vader\n",
    "analyser = \"vader\"\n",
    "# analyser = \"TextBlob\"\n",
    "#dataset grouped type - day or hour\n",
    "dataset_grouped_by = \"hour\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataset\n",
    "folder = \"./../../datasets/tweets_prices_volumes_sentiment/\" + \\\n",
    "    analyser+\"/\"+dataset_grouped_by+\"_datasets/cleaned\"\n",
    "filename = folder+\"/final_data_lag_\"+lag_granularity+\"_\" + \\\n",
    "    str(lag)+\".csv\" if (lag > 0) else folder+\"/final_data_no_lag.csv\"\n",
    "df = pd.read_csv(filename, index_col='DateTime', parse_dates=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group by datetime\n",
    "df = df.groupby('DateTime').agg(lambda x: x.mean())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tính toán các chỉ số indicator: rsi, ma\n",
    "#get change label\n",
    "df[\"Change\"] = (df[\"Close\"] > df[\"Close\"].shift(1)).astype(int)\n",
    "\n",
    "add_RSI = True\n",
    "add_longMAvg = True\n",
    "add_shortMAvg = True\n",
    "\n",
    "if(add_RSI):\n",
    "    #calcualte RSI\n",
    "    RSI = 14\n",
    "    df['RSI'] = rsi(df, RSI)\n",
    "    df = df.iloc[RSI:]\n",
    "\n",
    "#calculate moving averages\n",
    "if(add_shortMAvg):\n",
    "    short_window = 9\n",
    "    df['short_mavg'] = df.rolling(window=short_window)[\"Close\"].mean()\n",
    "\n",
    "if(add_longMAvg):\n",
    "    long_window = 21\n",
    "    df[\"long_mavg\"] = df.rolling(window=long_window)[\"Close\"].mean()\n",
    "\n",
    "if(add_longMAvg):\n",
    "    df = df.iloc[long_window:]\n",
    "elif(add_RSI):\n",
    "    df = df.iloc[RSI:]\n",
    "elif(add_shortMAvg):\n",
    "    df = df.iloc[short_window:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only wanted columns\n",
    "features = ['Change', 'subjectivity', 'polarity', 'Tweet_vol', 'Volume_(BTC)'] if analyser == \"Textblob\" else [\n",
    "    'Change', 'Close', 'pos_pol', 'neg_pol', 'Tweet_vol']\n",
    "\n",
    "if(add_RSI):\n",
    "    features.append(\"RSI\")\n",
    "\n",
    "if(add_longMAvg):\n",
    "    features.append(\"long_mavg\")\n",
    "\n",
    "if(add_shortMAvg):\n",
    "    features.append(\"short_mavg\")\n",
    "\n",
    "df = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot correlation matrix\n",
    "sn.heatmap(df.corr(), annot=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating copy so that data is not loaded once again\n",
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of previous records to consider for every example\n",
    "n_lag = 7\n",
    "#number of features\n",
    "n_features = len(features)\n",
    "#calculate total_features\n",
    "total_features = n_lag*n_features\n",
    "\n",
    "if(total_features == 0):\n",
    "    total_features = n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_lagged = df_copy\n",
    "data_with_lagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide df into train and test\n",
    "train_ratio = 0.85\n",
    "data_len = len(data_with_lagged)\n",
    "train_size = int(data_len*train_ratio)\n",
    "\n",
    "data_hours = data_with_lagged.iloc[:, :2].reset_index().drop(['DateTime'], axis=1)\n",
    "\n",
    "train = data_with_lagged.iloc[:train_size, :2]\n",
    "train = train.reset_index()\n",
    "train = train.drop(['DateTime'], axis=1)\n",
    "\n",
    "data_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chuẩn hóa\n",
    "xscaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train = xscaler.fit_transform(train)\n",
    "scaler_data = xscaler.transform(data_hours)\n",
    "print(train.shape, scaler_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(n_lag, len(train)):\n",
    "  X_train.append(train[i-n_lag:i, :])\n",
    "  y_train.append(train[i, :])\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(1)\n",
    "# tf.random.set_seed(1)\n",
    "\n",
    "# design network\n",
    "model_gru_hour_1 = Sequential()\n",
    "neurons = 64\n",
    "epochs = 50\n",
    "dropout = 0.25\n",
    "batch_size = 80\n",
    "activ_func = \"relu\"\n",
    "\n",
    "model_gru_hour_1.add(GRU(neurons, return_sequences=True, input_shape=(\n",
    "    X_train.shape[1], X_train.shape[2]), activation=activ_func))\n",
    "model_gru_hour_1.add(GRU(neurons, return_sequences=False))\n",
    "model_gru_hour_1.add(Dense(2))\n",
    "model_gru_hour_1.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping callback\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience =20)\n",
    "\n",
    "# fit network\n",
    "history = model_gru_hour_1.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tạo testing data set\n",
    "test_data = scaler_data[train_size - n_lag: , :]\n",
    "x_test = []\n",
    "y_test = data_with_lagged.iloc[train_size:, :2]\n",
    "\n",
    "for i in range(n_lag, len(test_data)):\n",
    "  x_test.append(test_data[i-n_lag:i, :])\n",
    "\n",
    "x_test = np.asarray(x_test)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the models predicted price value\n",
    "predictions = model_gru_hour_1.predict(x_test)\n",
    "predictions = xscaler.inverse_transform(predictions)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sai số\n",
    "mse = (((y_test - predictions)**2).mean())\n",
    "mae = np.abs((y_test - predictions).mean())\n",
    "mape = np.mean(np.abs((y_test - predictions) / y_test)) * 100\n",
    "smape = (100 / len(y_test)) * np.sum(2 * np.abs(predictions - y_test) / (np.abs(predictions) + np.abs(y_test)))\n",
    "\n",
    "print(mse[\"Close\"], mae[\"Close\"], mape[\"Close\"], smape[\"Close\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "valid = data_with_lagged[train_size:]\n",
    "valid['Predictions'] = predictions[:, 1]\n",
    "\n",
    "#hiển thị dữ liệu gần đây\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Model')\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Giá (USD)', fontsize=18)\n",
    "plt.plot(valid[['Close','Predictions']])\n",
    "plt.legend(['Val', 'Predictions'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create file if it does not exist\n",
    "data = {\n",
    "    'Model': 'GRU',\n",
    "    'Thông tin': ['MAE', 'MSE', 'MAPE', 'sMAPE'],\n",
    "    'Price': [mae[\"Close\"], mse[\"Close\"], mape[\"Close\"], smape[\"Close\"]],\n",
    "    # 'Price + Twitter': [mae1[\"Close\"], mse1[\"Close\"], mape1[\"Close\"], smape1[\"Close\"]],\n",
    "}\n",
    "result_table = pd.DataFrame(data)\n",
    "result_table.to_csv(\"result-hours.csv\", index=False)\n",
    "result_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
